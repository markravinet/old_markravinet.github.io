---
title: "Building on your foundations: going further with R"
output:
  html_document: default
  pdf_document: default
  word_document: default
---
```{r, eval = TRUE, echo = FALSE, message=FALSE}
library(tidyverse)
```

## What to expect

In this section we are going to: 

* explore more advanced methods of handling and manipulating data
* learn how to plot data using `ggplot2`
* introduce the benefits of writing R scripts
* learn some basic R programming techniques

## Introduction

In the last chapter, we got to grips with the basics of R. Hopefully after completing the basic introduction, you feel more comfortable with the key concepts of R. Don't worry if you feel like you haven't understood everything - this is common and perfectly normal! Learning R is very much like learning a real language in that it takes time and practice to feel 'fluent'. Even if you do feel comfortable in the language, there is no shame in asking for help or looking for more information to develop your understanding. As regular R users, we still look things up constantly and there are one or two basics which we still forget, even with over a decade of experience of using the R environemnt! With this in mind, a goal of these R tutorials is to re-emphasise and reinforce basic concepts throughtout. We will introduce concepts but through the practical demonstrations of code, we will underline them again and again. 

In future chapters, we will be using a similar approach to reinforce the evolutionary genetic concepts you have encountered in the book. However, for this chapter we remain solely in the R environment and will instead switch our focus to more advanced features of R. Advanced does not necessarily mean more complicated - but it does mean that you need to have at least been introduced to the basic concepts. We will first 'level-up' our approach to handling and manipulating data. For this, we will be borrowing heavily from the [tidyverse](https://www.tidyverse.org) - a collection of packages and principles for data science in R. We will also introduce you to more advanced plotting, comparing the two most popular apporaches for plots - `base` and `ggplot`.

We will also use this chapter to introduce some important features of programming. We start with the benefits of using an R script to keep track of your code and to reproduce your analysis. We will then turn to introducing some basic programming techniques and operations in R. We will also show you how to write your own custom functions. For those with no prior familiarity with programming, these initial ventures into writing functions and operations might seem a little daunting, but again, we aim to re-emphasise them as much as possible.

## More advanced manipulating and handling data 

Data manipulation might seem quite a boring topic but it is actually a crucial part of data science and increasingly, bioinformatics and evolutionary biology. For the average researcher working with biological data, we would estimate that the vast majority of analysis time is spent handling the data. By handling and manipulation, we mean exploring the data, shaping it into a form we want to work with and extracting information we find important or interesting. Getting to know your data is absolutely fundamental to properly understanding it and that is why we have decided to dedicate time to it in this chapter.

At this point in our tutorial, we will use a series of packages collectively known as the [tidyverse](https://www.tidyverse.org); in particularly, we will focus on functions from a tidyverse package calleed `dplyr`. These packages grew from the approach of [Hadley Wickham](http://hadley.nz/) - a statistician responsible for popularising fresh approaches to R and data science. As with nearly all things in R, there are many, many ways to achieve the same goal and the guidlines we give here are by no means definitive. However, we choose to introduce these principles now because in our experience of data analysis, they have greatly improved our efficiency, the clarity of our R code and the way we work with data.

Having used R for sometime, we have come to the tidyverse approach having already learned many of the basics in 'normal' or so-called 'baseR'. It can be difficult to shake off what you have already learned! This is one of the reasons we are keen to introduce you to these approaches early on - they will be much easier for you to take on board if you are less familiar with the 'standard' way of doing things. A brief note on approaches - there is a surprising amount of snobbery and elitism for approaches to coding and scripting - this is true for R and other programming languages. We wish to steer well clear of this, the most important thing is learning how to use the tools at your disposal effectively and efficiently. 

### Getting started with tidyverse packages

To go further, the very first thing we need to do is install and load the `tidyverse` package. Luckily, this is very straightforward! Run the following commands.

```{r, eval = FALSE, results = "hide"}
install.packages("tidyverse")
library(tidyverse)
```

As mentioned before, we will focus mainly on the `dplyr` package here - occassionally we might use some other packages and if we do, it will be stated clearly. The next thing we need to do, is get some data to work with. We will use the `starwars` data from `dplyr` - you may be noticing a theme here...

```{r, eval = TRUE, echo = TRUE}
starwars <- dplyr::starwars
```

What did we do here? We assigned the `starwars` dataset - specifying it was frome `dplr` using the `::` - that basically means, 'look inside `dplyr` for `starwars`'

If you take a look at the data by typing `starwars`, you will see it is stored as a `tibble`. This is a convenient way of displaying a `data.frame` and for all intents and purposes, behaves much the same way. It has the added advantage that it just shows you the first 10 lines of the data (known as the `head`). It also shows you what the data actually is - i.e. whether it is character data, integer, double or a factor. The tibble still behaves exactly as a it would as a standard `data.frame`. For example...

```{r, eval = FALSE, echo = TRUE}
starwars$name
```

...will produce a vector with the names of all the characters. Since the `tibble` only shows you the first 10 rows of your data, what if you want to see more? For that you can use the `print` function, like so:

```{r, eval = FALSE, echo = TRUE}
print(starwars, n = 15)
```

So now we have the package loaded and the data ready - we can start playing around with it!

### Selecting columns

Lets say we want to choose the name and homeworld columns from our `starwars` data, how can we do that? With standard R, we might do something like this.

```{r, eval = FALSE, echo = TRUE}
# with names
starwars[, c('name', 'homeworld')]
# with indices
starwars[, c(1, 9)]
```

With `dplyr` we can do the following:

```{r, eval = FALSE, echo = TRUE}
starwars %>% select(name, homeworld)
```

Wait a minute, what does `%>%` do!? This is a pipe - it essentially means, take the thing on the left and apply the function on the right to it. You can use it create chains of functions which you can easily apply to multiple data.frames if you need. It takes a bit of getting used to, but it can often clarify code. For consitency with standard R, we could have also written the code above like so:

```{r, eval = FALSE, echo = TRUE}
select(starwars, name, homeworld)
```

Both ways work and ultimately that is all that matters but for clarity and good practice, we will use the `%>%` pipe to make up our data handling workflows. So what else is going on with these two `tidyverse` inspired function calls? Well the function `select`, literally chooses columns from our `data.frame`. Hopefully the straightforwardness of this approach is a demonstration of how these packages can make R code more readable and easier to understand.

`select` is more powerful than just this. See some examples below:

```{r, eval = FALSE, echo = TRUE}
# choose all columns BUT name
starwars %>% select(-name)
# choose only columns containing an underscore
starwars %>% select(contains("_"))
# choose only columns beginning with "s"
starwars %>% select(starts_with("s"))
```

### Filtering data

We've seen now how to select columns using a `dplyr` approach - but what if we want to select rows? To do this, we need to filter the data on a given criteria. Let's say we want to just select humans from our `starwars` data. We can achieve this using a logical approach - i.e. extracting only rows which match our criteria - i.e. whether the individual is human in this case. Let's first see what happens when we apply a logical operation to the `species` column. Remember that for now, we will just use baseR.

```{r, eval = FALSE, echo = TRUE}
starwars$species == "Human"
```

All we did here is ask whether the species data is equal to the string 'Human'. This returned a logical vector of `TRUE` and `FALSE` values. If we now use this to subset our `data.frame`, R will only return rows where the value is `TRUE`. For example:

```{r, eval = FALSE, echo = TRUE}
starwars[starwars$species == "Human", ]
```

Note that you have to specify you mean species within the `starwars` data using a `$` operator, because otherwise R doesn't know where to look. In other words, the following will not work:

```{r, eval = FALSE, echo = TRUE}
starwars[species == "Human", ]
```

You should also note that we need a `==` instead of a `=` - this just means 'is equal to'. So what is the `dplyr` alternative? We can use the straightforwardly names `filter` function for this:

```{r, eval = FALSE, echo = TRUE}
starwars %>% filter(species == "Human")
```

Notice we use the `%>%` pipe again - the reason for this will hopefully become clear soon! You might be wondering at this point, that there doesn't seem to be a huge difference between these two approaches, other than the way the code looks. Where the `filter` command really becomes useful is when you use it for multiple different variables.

Let's suppose we want to extract all individuals that are Human and that are from Tatooine as their homeworld. With baseR, we would do the following:

```{r, eval = FALSE, echo = TRUE}
starwars[starwars$species == "Human" & starwars$homeworld == "Tatooine", ]
```

What about with `dplyr`? Well this would work:

```{r, eval = FALSE, echo = TRUE}
starwars %>% filter(species == "Human", homeworld == "Tatooine")
```

You can see how `dplyr` makes filtering on multiple variables much more straightforward and cleaner.

### Filtering AND selecting data

What if you want to do multiple things to a dataset at once? Perhaps you need to get your data into a certain format or just want to subset it to only the variables you are interested in. As you get more and more experienced with R, you will find this is something you want to do regularly. It makes sense to manage your data, stripping it down to the key values of interest. This is part of the principle of [tidy data](http://garrettgman.github.io/tidying/).

Let's return to our `starwars` dataset - what if we want to get the name, height and year of birth for all human species? If we use baseR, we would do it this way:

```{r, eval = FALSE, echo = TRUE}
starwars[starwars$species == "Human", c("name", "height", "birth_year")]
```

This sort of data manipulation requires us to first filter on the rows using `starwars$species == "Human"`. Remember back to Chapter 1, when we used square brackets to extract data from a matrix and then a data.frame? This is exactly the same thing. 

Next, we select the columns we want in the second part of the brackets using ` c("name", "height", "birth_year")`. This is fairly straightforward, even using baseR but you can imagine how this could be complicated if we wanted to select many different columns or filter on different variables.

What is the `dplyr` solution? 

```{r, eval = FALSE, echo = TRUE}
starwars %>% filter(species == "Human") %>% select(name, height, birth_year)
```

Here we just pipe the data to `filter` and then again to `select`. It is worth noting here that the `tidyverse` solution might not be particularly faster or even much less code. It is (in our opinion at least) easier to read and to disentangle, if you come back to the code at a later date. There really is no right or wrong way to manipulate data in R - whichever approach you use is ultimately a matter of taste. However as you will see in the next section, `dplyr` approaches can really level up your ability to manipulate data.

### Summarising data 

Where `dplyr` really excels is when you want to extract some kind of summary information from your data. Let's start with a very straightforward example using our `starwars` data. What if we want to count the number of different species there are in the data? First, let's actually look at the species present.

```{r, eval = FALSE, echo = TRUE}
starwars$species
```

You can see there are few different ones, although even from this it is fairly obvious humans are going to be the most numerous. If we want to count how many species there are, all we need to do is count the occurrence of each of these. Before we look at the `dplyr` solution, we will take a look at one more baseR way to achieve this.

```{r, eval = FALSE, echo = TRUE}
table(starwars$species)
```

This works and is fast but the main disadvantage is that our output is no longer a `data.frame`. It is also much more difficult to scale this approach up if we wish to group our dataset by multiple variables. But first, the `dplyr` equivalent of above is also straightforward:

```{r, eval = FALSE, echo = TRUE}
starwars %>% group_by(species) %>% tally()
```

All we have done here is first grouped our dataset by species using `group_by` and then counted the number of rows in each group using `tally`. 

`group_by` can really come into its own when you want to count or tally data based on several variables. Let's say we want to count the number of each gender of within each species. We would do it like so.

```{r, eval = FALSE, echo = TRUE}
starwars %>% group_by(species, gender) %>% tally()
```

We can do a lot more than just count occurrences with this functionality from `dplyr`. Perhaps we want to know the average height and mass of each species?

```{r, eval = FALSE, echo = TRUE}
starwars %>% group_by(species) %>% summarise(mean_height = mean(height, na.rm = T),
                                             mean_mass = mean(mass, na.rm = T))
```

Here all we did was use the `summarise` function to calculate mean height and mass. Since we used the `mean` function on both variables, we can actually simplify this even further like so:

```{r, eval = FALSE, echo = TRUE}
starwars %>% group_by(species) %>% summarise_at(vars(height, mass), mean, na.rm = T)
```

So this time we used `summarise_at` and specified the variables we wanted to summarise with the `vars` function. 

Summarising data in this way is a useful skill, especially when you want to get a feel for what your dataset shows or you need to break it down into more understandable subsets. As we turn next to more advanced plotting using `ggplot2`, you will see that manipulating data is especially useful when you want create certain types of plots. 
